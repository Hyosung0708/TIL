# 09.25 데이터 사이언스 스쿨 학습

## 02. 분류 모델 평가 방법, 03. 분류 알고리즘

### URL : https://colab.research.google.com/drive/17kxaWe9kkuLVYqV7usC4OTBU2ECvbXoi#scrollTo=XiZEHlLP9Zo7


### 과대적합 과소적합 꼭 알아둘 것

```shell

1.1.  과대적합(overfitting)이란?
과대적합(overfitting)이란 머신러닝 모델을 학습할 때 학습 데이터셋에 지나치게 최적화하여 발생하는 문제입니다. 즉, 모델을 지나치게 복잡하게 학습하여 학습 데이터셋에서는 모델 성능이 높게 나타나지만 정작 새로운 데이터가 주어졌을 때 정확한 예측/분류를 수행하지 못합니다.

 

아래 그림 1 내 좌측 그림 과 같이 어떤 지식/데이터가 주어졌다고 가정해 보겠습니다. 그림  1 내 가운데 그림 과 같이 경험적으로 어떤 관계/구조가 있다고 할 수 있습니다. 하지만, 만일 그림  1 내 우측 그림 과 같이 주어진 데이터를 특정한 조건/구조를 지나치게 반영하면 고양이나 강아지 그림이라고 창의적으로(creatively) 판단할 수도 있게 만듭니다. 이처럼 데이터셋의 특정 조건이나 구조를 과도하게 최적화하면 과대적합이 발생하게 됩니다.

1.2.  과소적합(underfitting)이란?
과소적합(underfitting)이란 과대적합의 반대 개념으로서 머신러닝 모델이 충분히 복잡하지 않아(최적화가 제대로 수행되지 않아) 학습 데이터의 구조/패턴을 정확히 반영하지 못하는 문제입니다.


2.3.1.  과소적합 발생 구간
먼저 모델이 단순할 때부터 살펴보겠습니다. 모델이 지나치게 단순하면 학습을 진행해도 학습 데이터의 특성을 제대로 반영하기 어렵기 때문에 train loss는 높게 나타납니다. 모델의 학습이 잘 수행된다는 가정 하에 일정 수준 전까지는 모델이 점차 복잡해질수록 train loss와 validation loss가 함께 감소하지만 연구자가 원하는 모델의 성능에 도달하기 전까지는 과소적합이 발생했다고 말합니다.


2.3.2.  과대적합 발생 구간
이처럼 모델이 점차 복잡해지면 train dataset에 따라 Gradient Descent 기법을 중심으로 모델이 학습되기 때문에 train loss는 꾸준히 감소합니다. 하지만 모델 복잡도가 일정 수준을 넘어감에 따라 모델이 training dataset에 overfitting 되면 오히려 validation loss가 증가하게 됩니다. 즉, validation loss가 감소하다가 증가하는 구간에서 과대적합이 발생했다고 말합니다.





```